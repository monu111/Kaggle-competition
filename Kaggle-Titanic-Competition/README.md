# Kaggle--Titanic-Competition

##Kaggle's Titanic Competition: Machine Learning from Disaster

The aim of this project is to predict which passengers survived the Titanic tragedy given a set of labeled data as the training dataset. 
Our strategy is to identify an informative set of features and then try different classification techniques to attain a good accuracy in predicting the class labels.

#### Results:

| Model                     | train dataset(validation accuracy)     | Accuracy (Kaggle  Test Dataset)  |
|-------------------------|:--------------------------------------:|-------------------------------:|
| 1. Logistic Regression    |  79%                                   |  75%                             |
| 2. Decision Tree          | 80%                                    |   73 %                           |
| 3. Random Forest          |  83%                                   |   76%                            |
| 4.  KNN                   |    79 %                                |   74%                            |
| 5.    SVM                 |      81%                               |   77%                            |

   

